--- a/fs/mpage.c	2016-06-03 12:56:43.000000000 +0300
+++ b/fs/mpage.c	2016-06-15 22:52:54.928036169 +0300
@@ -109,8 +109,8 @@
  * them.  So when the buffer is up to date and the page size == block size,
  * this marks the page up to date instead of adding new buffers.
  */
-static void
-map_buffer_to_page(struct page *page, struct buffer_head *bh, int page_block)
+static void 
+map_buffer_to_page(struct page *page, struct buffer_head *bh, int page_block) 
 {
 	struct inode *inode = page->mapping->host;
 	struct buffer_head *page_bh, *head;
@@ -121,9 +121,9 @@
 		 * don't make any buffers if there is only one buffer on
 		 * the page and the page just needs to be set up to date
 		 */
-		if (inode->i_blkbits == PAGE_CACHE_SHIFT &&
+		if (inode->i_blkbits == PAGE_CACHE_SHIFT && 
 		    buffer_uptodate(bh)) {
-			SetPageUptodate(page);
+			SetPageUptodate(page);    
 			return;
 		}
 		create_empty_buffers(page, 1 << inode->i_blkbits, 0);
@@ -240,7 +240,7 @@
 			map_buffer_to_page(page, map_bh, page_block);
 			goto confused;
 		}
-
+	
 		if (first_hole != blocks_per_page)
 			goto confused;		/* hole -> non-hole */
 
@@ -362,10 +362,6 @@
  *
  * This all causes the disk requests to be issued in the correct order.
  */
-#ifdef CONFIG_CMA
-extern void wakeup_wq(bool has_cma);
-extern bool has_cma_page(struct page *page);
-#endif
 int
 mpage_readpages(struct address_space *mapping, struct list_head *pages,
 				unsigned nr_pages, get_block_t get_block)
@@ -375,16 +371,7 @@
 	sector_t last_block_in_bio = 0;
 	struct buffer_head map_bh;
 	unsigned long first_logical_block = 0;
-#ifdef CONFIG_CMA
-	bool has_cma = false;
-	struct page * tmp_page = NULL;
-
-	list_for_each_entry(tmp_page, pages, lru){
-		has_cma = has_cma_page(tmp_page);
-		if (has_cma)
-			break;
-	}
-#endif
+
 	map_bh.b_state = 0;
 	map_bh.b_size = 0;
 	for (page_idx = 0; page_idx < nr_pages; page_idx++) {
@@ -402,9 +389,6 @@
 		}
 		page_cache_release(page);
 	}
-#ifdef CONFIG_CMA
-	wakeup_wq(has_cma);
-#endif
 	BUG_ON(!list_empty(pages));
 	if (bio)
 		mpage_bio_submit(READ, bio);
@@ -443,7 +427,7 @@
  *
  * If all blocks are found to be contiguous then the page can go into the
  * BIO.  Otherwise fall back to the mapping's writepage().
- *
+ * 
  * FIXME: This code wants an estimate of how many pages are still to be
  * written, so it can intelligently allocate a suitably-sized BIO.  For now,
  * just allocate full-size (16-page) BIOs.
@@ -728,3 +712,4 @@
 	return ret;
 }
 EXPORT_SYMBOL(mpage_writepage);
+
